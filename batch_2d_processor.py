"""
ë””ë ‰í† ë¦¬ ì¼ê´„ 2D ë¸”ë¡ ì²˜ë¦¬ê¸° + ê²°ê³¼ ì •ë¦¬ ì‹œìŠ¤í…œ
ëª¨ë“  FBX/OBJ íŒŒì¼ì„ 2D ì§ì‚¬ê°í˜•ìœ¼ë¡œ ë³€í™˜í•˜ê³  ë³´ê¸° ì¢‹ê²Œ ì •ë¦¬
"""
import trimesh
import numpy as np
import sys
import os
import time
import json
from pathlib import Path
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from collections import defaultdict, Counter
import warnings

warnings.filterwarnings('ignore')

# í”„ë¡œì íŠ¸ ëª¨ë“ˆ import
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, current_dir)

try:
    from models.voxel_block import VoxelBlock
    from models.placement_area import PlacementArea
    from algorithms.backtracking_placer import BacktrackingPlacer
    from utils.visualizer import Visualizer
    print(f"[INFO] Project modules loaded successfully")
except ImportError as e:
    print(f"[ERROR] Cannot find project modules: {e}")
    print(f"[INFO] Continuing without placement testing...")

class BatchBlock2DProcessor:
    """ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  ë¸”ë¡ì„ 2Dë¡œ ì¼ê´„ ì²˜ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self, grid_resolution=2.0, output_dir="2d_blocks_output"):
        """
        Args:
            grid_resolution (float): ê·¸ë¦¬ë“œ í•´ìƒë„ (m)
            output_dir (str): ê²°ê³¼ ì €ì¥ ë””ë ‰í† ë¦¬
        """
        self.grid_resolution = grid_resolution
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # ê²°ê³¼ ì €ì¥ìš©
        self.processed_blocks = []
        self.processing_stats = {
            'total_files': 0,
            'successful': 0,
            'failed': 0,
            'skipped': 0,
            'start_time': None,
            'end_time': None
        }
        self.error_log = []
    
    def find_mesh_files(self, directory):
        """ë””ë ‰í† ë¦¬ì—ì„œ ë©”ì‹œ íŒŒì¼ë“¤ ì°¾ê¸°"""
        directory = Path(directory)
        
        if not directory.exists():
            print(f"âŒ Directory not found: {directory}")
            return []
        
        # ì§€ì›í•˜ëŠ” íŒŒì¼ í™•ì¥ì (FBX í¬í•¨)
        supported_extensions = ['.fbx', '.obj', '.ply', '.stl', '.dae', '.3ds']
        
        mesh_files = []
        for ext in supported_extensions:
            mesh_files.extend(list(directory.glob(f"*{ext}")))
            mesh_files.extend(list(directory.glob(f"*{ext.upper()}")))
        
        # ì¤‘ë³µ ì œê±° ë° ì •ë ¬
        mesh_files = sorted(list(set(mesh_files)))
        
        print(f"ğŸ“ Found {len(mesh_files)} mesh files in {directory}")
        if len(mesh_files) > 0:
            print(f"   Extensions: {set(f.suffix.lower() for f in mesh_files)}")
            
            # FBX íŒŒì¼ì´ ìˆìœ¼ë©´ Blender í•„ìš” ì•Œë¦¼
            fbx_files = [f for f in mesh_files if f.suffix.lower() == '.fbx']
            if fbx_files:
                print(f"   ğŸ”„ Found {len(fbx_files)} FBX files - will auto-convert with Blender")
        
        return mesh_files
    
    def process_single_mesh_to_2d(self, file_path):
        """ë‹¨ì¼ ë©”ì‹œ íŒŒì¼ì„ 2D ë¸”ë¡ìœ¼ë¡œ ë³€í™˜"""
        try:
            # 1. FBX íŒŒì¼ì¸ ê²½ìš° ë¨¼ì € OBJë¡œ ë³€í™˜
            actual_file_path = file_path
            if file_path.suffix.lower() == '.fbx':
                print(f"    ğŸ”„ Converting FBX to OBJ...")
                obj_path = self._convert_fbx_to_obj(file_path)
                if obj_path and obj_path.exists():
                    actual_file_path = obj_path
                    print(f"    âœ… FBX conversion successful")
                else:
                    raise Exception("FBX to OBJ conversion failed")
            
            # 2. ë©”ì‹œ ë¡œë“œ
            mesh = trimesh.load(actual_file_path)
            
            # ë©”ì‹œ í’ˆì§ˆ ê°œì„ 
            if hasattr(mesh, 'vertices') and hasattr(mesh, 'faces'):
                mesh.merge_vertices()
                mesh.remove_degenerate_faces()
                mesh.remove_duplicate_faces()
            
            # 2. ë°”ìš´ë”© ë°•ìŠ¤ ê³„ì‚°
            bbox_3d = mesh.bounds
            
            # 3. X, Y í¬ê¸° ì¶”ì¶œ
            x_size = bbox_3d[1][0] - bbox_3d[0][0]
            y_size = bbox_3d[1][1] - bbox_3d[0][1]
            z_size = bbox_3d[1][2] - bbox_3d[0][2]
            
            # 4. ê·¸ë¦¬ë“œ ë‹¨ìœ„ë¡œ ë³€í™˜
            grid_x = max(1, round(x_size / self.grid_resolution))
            grid_y = max(1, round(y_size / self.grid_resolution))
            
            # 5. 2D ë³µì…€ ë°ì´í„° ìƒì„±
            voxel_data_2d = []
            for x in range(grid_x):
                for y in range(grid_y):
                    voxel_data_2d.append((x, y, [0, 1, 0]))
            
            # 6. VoxelBlock ìƒì„±
            block_id = file_path.stem
            voxel_block = VoxelBlock(block_id, voxel_data_2d)
            
            # 7. ì¶”ê°€ ì •ë³´ ì €ì¥
            block_info = {
                'file_path': str(file_path),
                'block_id': block_id,
                'file_size_mb': file_path.stat().st_size / 1024 / 1024,
                'vertices_count': len(mesh.vertices) if hasattr(mesh, 'vertices') else 0,
                'faces_count': len(mesh.faces) if hasattr(mesh, 'faces') else 0,
                'original_size_3d': {
                    'x': float(x_size),
                    'y': float(y_size),
                    'z': float(z_size)
                },
                'grid_size_2d': {
                    'width': grid_x,
                    'height': grid_y
                },
                'actual_size_2d': {
                    'width': grid_x * self.grid_resolution,
                    'height': grid_y * self.grid_resolution
                },
                'area_cells': grid_x * grid_y,
                'area_m2': (grid_x * self.grid_resolution) * (grid_y * self.grid_resolution)
            }
            
            return voxel_block, block_info, None
            
        except Exception as e:
            error_msg = f"Failed to process {file_path.name}: {str(e)}"
            return None, None, error_msg
    
    def _convert_fbx_to_obj(self, fbx_path):
        """FBXë¥¼ OBJë¡œ ë³€í™˜ (Blender ì‚¬ìš©)"""
        try:
            # OBJ íŒŒì¼ ì €ì¥ ê²½ë¡œ (converted_obj í´ë”ì— ì €ì¥)
            converted_dir = fbx_path.parent / "converted_obj"
            converted_dir.mkdir(exist_ok=True)
            obj_path = converted_dir / fbx_path.with_suffix('.obj').name
            
            # ì´ë¯¸ ë³€í™˜ëœ OBJ íŒŒì¼ì´ ìˆìœ¼ë©´ ì‚¬ìš©
            if obj_path.exists():
                obj_time = obj_path.stat().st_mtime
                fbx_time = fbx_path.stat().st_mtime
                if obj_time > fbx_time:  # OBJê°€ ë” ìµœì‹ ì´ë©´
                    print(f"        ğŸ“ Using cached OBJ: {obj_path.name}")
                    return obj_path
            
            # Blenderë¡œ ë³€í™˜
            print(f"        ğŸ”„ Converting to: {obj_path.relative_to(fbx_path.parent)}")
            success = self._run_blender_conversion(fbx_path, obj_path)
            
            if success and obj_path.exists():
                return obj_path
            else:
                return None
                
        except Exception as e:
            print(f"        âŒ FBX conversion error: {e}")
            return None
    
    def _run_blender_conversion(self, fbx_path, obj_path):
        """Blenderë¥¼ ì‹¤í–‰í•´ì„œ FBX â†’ OBJ ë³€í™˜"""
        try:
            import subprocess
            import tempfile
            
            # Blender ìŠ¤í¬ë¦½íŠ¸ ìƒì„±
            blender_script = f'''
import bpy
import sys

# FBX ì„í¬íŠ¸
bpy.ops.wm.read_factory_settings(use_empty=True)
try:
    bpy.ops.import_scene.fbx(filepath="{str(fbx_path).replace(chr(92), "/")}")
    # OBJ ìµìŠ¤í¬íŠ¸
    bpy.ops.wm.obj_export(
        filepath="{str(obj_path).replace(chr(92), "/")}",
        export_selected_objects=True,
        export_uv=False,
        export_normals=True,
        export_materials=False,
        export_triangulated_mesh=True
    )
    print("SUCCESS: FBX to OBJ conversion completed")
except Exception as e:
    print(f"ERROR: {{e}}")
    sys.exit(1)
'''
            
            # ì„ì‹œ ìŠ¤í¬ë¦½íŠ¸ íŒŒì¼ ìƒì„±
            with tempfile.NamedTemporaryFile(mode='w', suffix='.py', delete=False) as f:
                f.write(blender_script)
                script_path = f.name
            
            # Blender ì‹¤í–‰
            blender_paths = [
                "blender",  # PATHì— ìˆëŠ” ê²½ìš°
                r"C:\Program Files\Blender Foundation\Blender 4.0\blender.exe",
                r"C:\Program Files\Blender Foundation\Blender 3.6\blender.exe",
                "/Applications/Blender.app/Contents/MacOS/Blender",
                "/usr/bin/blender"
            ]
            
            for blender_path in blender_paths:
                try:
                    cmd = [
                        blender_path,
                        "--background",
                        "--python", script_path
                    ]
                    
                    result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
                    
                    # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                    try:
                        os.unlink(script_path)
                    except:
                        pass
                    
                    if result.returncode == 0 and "SUCCESS" in result.stdout:
                        return True
                    
                except (subprocess.TimeoutExpired, FileNotFoundError):
                    continue
            
            # ëª¨ë“  Blender ê²½ë¡œê°€ ì‹¤íŒ¨í•œ ê²½ìš°
            print(f"        âš ï¸ Blender not found. Please install Blender or add to PATH")
            return False
            
        except Exception as e:
            print(f"        âŒ Blender execution error: {e}")
            return False
    
    def classify_block_by_name(self, block_id):
        """ë¸”ë¡ ì´ë¦„ìœ¼ë¡œ ìœ í˜• ë¶„ë¥˜"""
        # íŒŒì¼ëª…ì—ì„œ ë¸”ë¡ ë²ˆí˜¸ ì¶”ì¶œ ì‹œë„
        block_id_lower = block_id.lower()
        
        # íŒ¨í„´ ë§¤ì¹­
        if any(char.isalpha() for char in block_id):
            # ì˜ë¬¸ í¬í•¨ (ì˜ˆ: 20F, 20G, 20Y, 40A)
            return "crane"
        elif block_id.isdigit():
            # ìˆœìˆ˜ ìˆ«ì
            if len(block_id) <= 2:
                return "crane"  # 10ë‹¨ìœ„
            else:
                return "trestle"  # 100ë‹¨ìœ„
        else:
            # ë³µí•© íŒ¨í„´ (ì˜ˆ: 4386_183_000)
            parts = block_id.replace('_', '').replace('-', '')
            if any(part.isdigit() and len(part) >= 3 for part in parts.split()):
                return "trestle"
            else:
                return "crane"
    
    def process_directory(self, directory):
        """ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  ë©”ì‹œ íŒŒì¼ì„ 2Dë¡œ ë³€í™˜"""
        print(f"\nğŸš€ Starting batch 2D block processing...")
        print(f"ğŸ“ Directory: {directory}")
        print(f"ğŸ“ Grid resolution: {self.grid_resolution}m")
        print(f"ğŸ’¾ Output: {self.output_dir}")
        print("="*80)
        
        # ì‹œì‘ ì‹œê°„ ê¸°ë¡
        self.processing_stats['start_time'] = time.time()
        
        # ë©”ì‹œ íŒŒì¼ë“¤ ì°¾ê¸°
        mesh_files = self.find_mesh_files(directory)
        self.processing_stats['total_files'] = len(mesh_files)
        
        if not mesh_files:
            print("âŒ No mesh files found!")
            return
        
        # ê° íŒŒì¼ ì²˜ë¦¬
        print(f"\nğŸ”„ Processing {len(mesh_files)} files...")
        for i, file_path in enumerate(mesh_files, 1):
            print(f"\nğŸ“¦ [{i:3d}/{len(mesh_files)}] {file_path.name}")
            
            # íŒŒì¼ í¬ê¸° ì²´í¬
            file_size_mb = file_path.stat().st_size / 1024 / 1024
            print(f"    ğŸ’¾ Size: {file_size_mb:.1f}MB")
            
            # ë„ˆë¬´ í° íŒŒì¼ì€ ê±´ë„ˆë›°ê¸° (500MB ì´ìƒ)
            if file_size_mb > 500:
                print(f"    âš ï¸ Skipped: File too large (>{500}MB)")
                self.processing_stats['skipped'] += 1
                continue
            
            # ì²˜ë¦¬ ì‹œì‘
            start_time = time.time()
            voxel_block, block_info, error = self.process_single_mesh_to_2d(file_path)
            elapsed_time = time.time() - start_time
            
            if voxel_block and block_info:
                # ì„±ê³µ
                block_info['processing_time'] = elapsed_time
                block_info['block_type'] = self.classify_block_by_name(block_info['block_id'])
                
                self.processed_blocks.append({
                    'voxel_block': voxel_block,
                    'info': block_info
                })
                
                self.processing_stats['successful'] += 1
                
                print(f"    âœ… Success: {block_info['grid_size_2d']['width']}Ã—{block_info['grid_size_2d']['height']} "
                      f"({block_info['area_cells']} cells, {elapsed_time:.1f}s, {block_info['block_type']})")
            else:
                # ì‹¤íŒ¨
                self.error_log.append({
                    'file': str(file_path),
                    'error': error,
                    'timestamp': time.time()
                })
                self.processing_stats['failed'] += 1
                print(f"    âŒ Failed: {error}")
        
        # ì¢…ë£Œ ì‹œê°„ ê¸°ë¡
        self.processing_stats['end_time'] = time.time()
        
        print(f"\nğŸ‰ Batch processing complete!")
        self._print_processing_summary()
        
        # ê²°ê³¼ ì €ì¥
        self._save_results()
        
        # ì‹œê°í™” ìƒì„±
        self._create_visualizations()
        
        return self.processed_blocks
    
    def _print_processing_summary(self):
        """ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        total_time = self.processing_stats['end_time'] - self.processing_stats['start_time']
        
        print("\nğŸ“Š PROCESSING SUMMARY")
        print("="*50)
        print(f"â±ï¸  Total time: {total_time:.1f}s")
        print(f"ğŸ“ Total files: {self.processing_stats['total_files']}")
        print(f"âœ… Successful: {self.processing_stats['successful']}")
        print(f"âŒ Failed: {self.processing_stats['failed']}")
        print(f"âš ï¸  Skipped: {self.processing_stats['skipped']}")
        print(f"ğŸ“ˆ Success rate: {self.processing_stats['successful']/max(1,self.processing_stats['total_files'])*100:.1f}%")
        
        if self.processed_blocks:
            # ë¸”ë¡ í†µê³„
            crane_blocks = [b for b in self.processed_blocks if b['info']['block_type'] == 'crane']
            trestle_blocks = [b for b in self.processed_blocks if b['info']['block_type'] == 'trestle']
            
            total_area = sum(b['info']['area_cells'] for b in self.processed_blocks)
            avg_area = total_area / len(self.processed_blocks)
            
            print(f"\nğŸ—ï¸  Block Statistics:")
            print(f"    ğŸ”§ Crane blocks: {len(crane_blocks)}")
            print(f"    ğŸšš Trestle blocks: {len(trestle_blocks)}")
            print(f"    ğŸ“ Average area: {avg_area:.1f} cells")
            print(f"    ğŸ“Š Total area: {total_area:,} cells")
            
            # í¬ê¸° ë¶„í¬
            sizes = [f"{b['info']['grid_size_2d']['width']}Ã—{b['info']['grid_size_2d']['height']}" 
                    for b in self.processed_blocks]
            size_counts = Counter(sizes)
            print(f"    ğŸ“ Most common sizes:")
            for size, count in size_counts.most_common(5):
                print(f"        {size}: {count} blocks")
    
    def _save_results(self):
        """ê²°ê³¼ë¥¼ ë‹¤ì–‘í•œ í˜•íƒœë¡œ ì €ì¥"""
        print(f"\nğŸ’¾ Saving results to {self.output_dir}...")
        
        # 1. JSON ìƒì„¸ ì •ë³´ ì €ì¥
        json_data = {
            'processing_stats': self.processing_stats,
            'blocks': [b['info'] for b in self.processed_blocks],
            'errors': self.error_log,
            'metadata': {
                'grid_resolution': self.grid_resolution,
                'timestamp': time.time(),
                'total_blocks': len(self.processed_blocks)
            }
        }
        
        json_path = self.output_dir / 'block_processing_results.json'
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, indent=2, ensure_ascii=False)
        print(f"    ğŸ’¾ JSON: {json_path}")
        
        # 2. CSV ìš”ì•½ ì •ë³´ ì €ì¥
        if self.processed_blocks:
            csv_data = []
            for block_data in self.processed_blocks:
                info = block_data['info']
                csv_data.append({
                    'block_id': info['block_id'],
                    'block_type': info['block_type'],
                    'grid_width': info['grid_size_2d']['width'],
                    'grid_height': info['grid_size_2d']['height'],
                    'area_cells': info['area_cells'],
                    'area_m2': info['area_m2'],
                    'original_x': info['original_size_3d']['x'],
                    'original_y': info['original_size_3d']['y'],
                    'original_z': info['original_size_3d']['z'],
                    'vertices': info['vertices_count'],
                    'faces': info['faces_count'],
                    'file_size_mb': info['file_size_mb'],
                    'processing_time': info['processing_time']
                })
            
            df = pd.DataFrame(csv_data)
            csv_path = self.output_dir / 'blocks_summary.csv'
            df.to_csv(csv_path, index=False, encoding='utf-8-sig')
            print(f"    ğŸ“Š CSV: {csv_path}")
        
        # 3. í…ìŠ¤íŠ¸ ë¦¬í¬íŠ¸ ì €ì¥
        report_path = self.output_dir / 'processing_report.txt'
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("ğŸš€ 2D BLOCK PROCESSING REPORT\n")
            f.write("="*50 + "\n\n")
            
            # ì²˜ë¦¬ í†µê³„
            f.write("ğŸ“Š PROCESSING STATISTICS\n")
            f.write("-"*30 + "\n")
            f.write(f"Total files: {self.processing_stats['total_files']}\n")
            f.write(f"Successful: {self.processing_stats['successful']}\n")
            f.write(f"Failed: {self.processing_stats['failed']}\n")
            f.write(f"Skipped: {self.processing_stats['skipped']}\n")
            f.write(f"Success rate: {self.processing_stats['successful']/max(1,self.processing_stats['total_files'])*100:.1f}%\n\n")
            
            # ë¸”ë¡ ëª©ë¡
            if self.processed_blocks:
                f.write("ğŸ“¦ PROCESSED BLOCKS\n")
                f.write("-"*30 + "\n")
                for block_data in self.processed_blocks:
                    info = block_data['info']
                    f.write(f"{info['block_id']:20} | {info['block_type']:8} | "
                           f"{info['grid_size_2d']['width']:2}Ã—{info['grid_size_2d']['height']:2} | "
                           f"{info['area_cells']:3} cells | {info['processing_time']:.1f}s\n")
            
            # ì—ëŸ¬ ëª©ë¡
            if self.error_log:
                f.write(f"\nâŒ ERRORS ({len(self.error_log)})\n")
                f.write("-"*30 + "\n")
                for error in self.error_log:
                    f.write(f"{Path(error['file']).name}: {error['error']}\n")
        
        print(f"    ğŸ“„ Report: {report_path}")
    
    def _create_visualizations(self):
        """ì²˜ë¦¬ ê²°ê³¼ ì‹œê°í™” ìƒì„±"""
        if not self.processed_blocks:
            return
        
        print(f"\nğŸ¨ Creating visualizations...")
        
        # ê·¸ë¦¼ í¬ê¸° ì„¤ì •
        fig = plt.figure(figsize=(20, 12))
        
        # 1. ë¸”ë¡ í¬ê¸° ë¶„í¬ (2Ã—2 ê·¸ë¦¬ë“œì˜ ì²« ë²ˆì§¸)
        ax1 = plt.subplot(2, 3, 1)
        areas = [b['info']['area_cells'] for b in self.processed_blocks]
        ax1.hist(areas, bins=min(20, len(set(areas))), alpha=0.7, color='skyblue', edgecolor='black')
        ax1.set_xlabel('Area (cells)')
        ax1.set_ylabel('Count')
        ax1.set_title('ğŸ“ Block Size Distribution')
        ax1.grid(True, alpha=0.3)
        
        # 2. ë¸”ë¡ ìœ í˜• ë¶„í¬ (íŒŒì´ ì°¨íŠ¸)
        ax2 = plt.subplot(2, 3, 2)
        type_counts = Counter(b['info']['block_type'] for b in self.processed_blocks)
        colors = ['lightcoral', 'lightblue', 'lightgreen']
        wedges, texts, autotexts = ax2.pie(type_counts.values(), labels=type_counts.keys(), 
                                          autopct='%1.1f%%', colors=colors[:len(type_counts)])
        ax2.set_title('ğŸ—ï¸ Block Type Distribution')
        
        # 3. ì²˜ë¦¬ ì‹œê°„ ë¶„í¬
        ax3 = plt.subplot(2, 3, 3)
        times = [b['info']['processing_time'] for b in self.processed_blocks]
        ax3.scatter(range(len(times)), times, alpha=0.6, c='orange')
        ax3.set_xlabel('Block Index')
        ax3.set_ylabel('Processing Time (s)')
        ax3.set_title('â±ï¸ Processing Time')
        ax3.grid(True, alpha=0.3)
        
        # 4. ë¸”ë¡ í¬ê¸° vs ì²˜ë¦¬ ì‹œê°„
        ax4 = plt.subplot(2, 3, 4)
        vertices = [b['info']['vertices_count'] for b in self.processed_blocks]
        ax4.scatter(vertices, times, alpha=0.6, c='green')
        ax4.set_xlabel('Vertices Count')
        ax4.set_ylabel('Processing Time (s)')
        ax4.set_title('ğŸ”º Vertices vs Processing Time')
        ax4.grid(True, alpha=0.3)
        
        # 5. 2D ë¸”ë¡ ë°°ì¹˜ ë¯¸ë¦¬ë³´ê¸° (ì¼ë¶€ë§Œ)
        ax5 = plt.subplot(2, 3, 5)
        preview_blocks = self.processed_blocks[:12]  # ì²˜ìŒ 12ê°œë§Œ
        
        cols = 4
        rows = 3
        colors = plt.cm.Set3(np.linspace(0, 1, len(preview_blocks)))
        
        for i, block_data in enumerate(preview_blocks):
            row = i // cols
            col = i % cols
            
            info = block_data['info']
            width = info['grid_size_2d']['width']
            height = info['grid_size_2d']['height']
            
            # ìœ„ì¹˜ ê³„ì‚°
            x = col * 6
            y = (rows - 1 - row) * 6
            
            # ë¸”ë¡ ê·¸ë¦¬ê¸°
            rect = patches.Rectangle((x, y), width, height, 
                                   linewidth=1, edgecolor='black', 
                                   facecolor=colors[i], alpha=0.7)
            ax5.add_patch(rect)
            
            # ë¸”ë¡ ID í‘œì‹œ
            ax5.text(x + width/2, y + height/2, info['block_id'][:8], 
                    ha='center', va='center', fontsize=6, fontweight='bold')
        
        ax5.set_xlim(0, cols * 6)
        ax5.set_ylim(0, rows * 6)
        ax5.set_aspect('equal')
        ax5.set_title('ğŸ“¦ Block Preview (First 12)')
        ax5.grid(True, alpha=0.3)
        
        # 6. ìš”ì•½ í†µê³„ í…ìŠ¤íŠ¸
        ax6 = plt.subplot(2, 3, 6)
        ax6.axis('off')
        
        total_area = sum(b['info']['area_cells'] for b in self.processed_blocks)
        avg_area = total_area / len(self.processed_blocks)
        total_time = sum(b['info']['processing_time'] for b in self.processed_blocks)
        
        stats_text = f"""
ğŸ“Š SUMMARY STATISTICS

ğŸ”¢ Total Blocks: {len(self.processed_blocks)}
ğŸ“ Total Area: {total_area:,} cells
ğŸ“ Average Area: {avg_area:.1f} cells
â±ï¸ Total Processing: {total_time:.1f}s
ğŸ“ˆ Success Rate: {self.processing_stats['successful']/max(1,self.processing_stats['total_files'])*100:.1f}%

ğŸ—ï¸ Block Types:
"""
        
        type_counts = Counter(b['info']['block_type'] for b in self.processed_blocks)
        for block_type, count in type_counts.items():
            stats_text += f"   {block_type}: {count}\n"
        
        ax6.text(0.1, 0.9, stats_text, transform=ax6.transAxes, fontsize=10, 
                verticalalignment='top', fontfamily='monospace',
                bbox=dict(boxstyle="round,pad=0.5", facecolor="lightgray"))
        
        plt.suptitle('ğŸ¯ 2D Block Processing Results Dashboard', fontsize=16, fontweight='bold')
        plt.tight_layout()
        
        # ì €ì¥
        viz_path = self.output_dir / 'processing_dashboard.png'
        plt.savefig(viz_path, dpi=300, bbox_inches='tight')
        plt.show()
        
        print(f"    ğŸ¨ Dashboard: {viz_path}")
    
    def get_blocks_for_placement(self):
        """ë°°ì¹˜ ì•Œê³ ë¦¬ì¦˜ìš© ë¸”ë¡ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
        if not self.processed_blocks:
            return []
        
        # VoxelBlock ê°ì²´ë“¤ë§Œ ì¶”ì¶œ
        blocks = [b['voxel_block'] for b in self.processed_blocks]
        
        # ë¸”ë¡ì— ì¶”ê°€ ì •ë³´ ì²¨ë¶€
        for i, block_data in enumerate(self.processed_blocks):
            blocks[i].block_type = block_data['info']['block_type']
            blocks[i].original_info = block_data['info']
        
        return blocks

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    if len(sys.argv) < 2:
        print("ğŸš€" + "="*70)
        print("BATCH 2D BLOCK PROCESSOR")
        print("ğŸš€" + "="*70)
        print("")
        print("ì‚¬ìš©ë²•:")
        print("  python batch_2d_processor.py <directory>")
        print("  python batch_2d_processor.py <directory> <resolution>")
        print("  python batch_2d_processor.py <directory> <resolution> <output_dir>")
        print("")
        print("ì˜ˆì‹œ:")
        print("  python batch_2d_processor.py fbx_blocks/")
        print("  python batch_2d_processor.py models/ 1.5")
        print("  python batch_2d_processor.py blocks/ 2.0 results/")
        print("")
        print("âœ¨ ê¸°ëŠ¥:")
        print("  ğŸ“ ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  ë©”ì‹œ íŒŒì¼ ì¼ê´„ ì²˜ë¦¬")
        print("  ğŸ“ 2D ì§ì‚¬ê°í˜• ë¸”ë¡ìœ¼ë¡œ ë³€í™˜")
        print("  ğŸ—ï¸ í¬ë ˆì¸/íŠ¸ë ˆìŠ¬ ë¸”ë¡ ìë™ ë¶„ë¥˜")
        print("  ğŸ“Š ìƒì„¸ í†µê³„ ë° ì‹œê°í™”")
        print("  ğŸ’¾ JSON, CSV, TXT ê²°ê³¼ ì €ì¥")
        print("  ğŸ¨ ëŒ€ì‹œë³´ë“œ ì°¨íŠ¸ ìƒì„±")
        return
    
    # ì¸ìˆ˜ íŒŒì‹±
    directory = sys.argv[1]
    resolution = float(sys.argv[2]) if len(sys.argv) > 2 else 2.0
    output_dir = sys.argv[3] if len(sys.argv) > 3 else "2d_blocks_output"
    
    try:
        print("ğŸš€" + "="*70)
        print("BATCH 2D BLOCK PROCESSOR")
        print("ğŸš€" + "="*70)
        
        # ì²˜ë¦¬ê¸° ìƒì„±
        processor = BatchBlock2DProcessor(
            grid_resolution=resolution,
            output_dir=output_dir
        )
        
        # ì¼ê´„ ì²˜ë¦¬ ì‹¤í–‰
        processed_blocks = processor.process_directory(directory)
        
        if processed_blocks:
            print(f"\nğŸ‰ === PROCESSING COMPLETE! ===")
            print(f"âœ… Successfully processed {len(processed_blocks)} blocks")
            print(f"ğŸ“ Results saved to: {processor.output_dir}")
            print(f"ğŸ¨ Dashboard chart created")
            
            # ë°°ì¹˜ ì•Œê³ ë¦¬ì¦˜ í…ŒìŠ¤íŠ¸ ì œì•ˆ
            print(f"\nğŸ’¡ Next Steps:")
            print(f"  ğŸ”§ Use processed blocks with placement algorithm")
            print(f"  ğŸ“Š Check dashboard: {processor.output_dir}/processing_dashboard.png")
            print(f"  ğŸ“‹ Review CSV: {processor.output_dir}/blocks_summary.csv")
            
            # ê°„ë‹¨í•œ ë°°ì¹˜ í…ŒìŠ¤íŠ¸ (ì„ íƒì‚¬í•­)
            try:
                blocks = processor.get_blocks_for_placement()
                if len(blocks) > 0:
                    print(f"\nğŸ§ª Testing placement with first 5 blocks...")
                    
                    # ìí•­ì„  í¬ê¸°: 84mÃ—36m = 42Ã—18 ê·¸ë¦¬ë“œ
                    test_area = PlacementArea(width=42, height=18)
                    test_blocks = blocks[:5]  # ì²˜ìŒ 5ê°œë§Œ í…ŒìŠ¤íŠ¸
                    
                    placer = BacktrackingPlacer(test_area, test_blocks, max_time=10)
                    result = placer.optimize()
                    
                    if result:
                        print(f"    âœ… Placement test successful!")
                        print(f"    ğŸ“¦ Placed: {len(result.placed_blocks)}/{len(test_blocks)} blocks")
                        print(f"    ğŸ“Š Score: {result.get_placement_score():.3f}")
                    else:
                        print(f"    âš ï¸ Placement test: no solution found")
            except:
                print(f"    â„¹ï¸ Placement test skipped (modules not available)")
        
        else:
            print(f"\nğŸ’¡ Processing completed but no blocks were successfully converted.")
            print(f"ğŸ“‹ Check error log: {processor.output_dir}/processing_report.txt")
        
        input("\nì•„ë¬´ í‚¤ë‚˜ ëˆŒëŸ¬ì„œ ì¢…ë£Œ...")
        
    except KeyboardInterrupt:
        print(f"\nâš ï¸ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë¨")
    except Exception as e:
        print(f"\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()